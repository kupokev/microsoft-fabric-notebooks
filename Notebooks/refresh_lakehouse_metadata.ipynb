{"cells":[{"cell_type":"code","source":["from concurrent.futures import ThreadPoolExecutor\n","from datetime import datetime"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":49,"statement_ids":[49],"state":"finished","livy_statement_state":"available","session_id":"219fdb7d-abb8-4ba0-95f0-b34ffba044e7","normalized_state":"finished","queued_time":"2025-09-26T23:47:24.730945Z","session_start_time":null,"execution_start_time":"2025-09-26T23:47:24.7321834Z","execution_finish_time":"2025-09-26T23:47:25.0571167Z","parent_msg_id":"b607114c-9cbe-4ba5-8161-d8ff69ed0f76"},"text/plain":"StatementMeta(, 219fdb7d-abb8-4ba0-95f0-b34ffba044e7, 49, Finished, Available, Finished)"},"metadata":{}}],"execution_count":47,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7ef1c680-93d4-4126-84cf-793ac5d6f0bc"},{"cell_type":"markdown","source":["### Functions"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"68e38f61-780e-49cf-a57c-94a228c7d071"},{"cell_type":"code","source":["def get_table_list():\n","    # Get default lakehouse name\n","    lakehouse_name = notebookutils.runtime.context.get(\"defaultLakehouseName\")\n","\n","    # Get list of tables from lakehouse\n","    tables = notebookutils.lakehouse.listTables(lakehouse_name)\n","\n","    return [table.name for table in tables] "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":50,"statement_ids":[50],"state":"finished","livy_statement_state":"available","session_id":"219fdb7d-abb8-4ba0-95f0-b34ffba044e7","normalized_state":"finished","queued_time":"2025-09-26T23:47:24.8530715Z","session_start_time":null,"execution_start_time":"2025-09-26T23:47:25.0605042Z","execution_finish_time":"2025-09-26T23:47:25.3774825Z","parent_msg_id":"0d0c54f7-3689-4996-8411-e48ed1413b6a"},"text/plain":"StatementMeta(, 219fdb7d-abb8-4ba0-95f0-b34ffba044e7, 50, Finished, Available, Finished)"},"metadata":{}}],"execution_count":48,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cf91ffe1-7b14-4544-81fb-f9fc6e1adb5c"},{"cell_type":"code","source":["def refresh_table(table_name):\n","    try:\n","        print(f\"[{datetime.now()}] Starting refresh for table: {table_name}\")\n","        \n","        # If you need to run OPTIMIZE or VACUUM:\n","        spark.sql(f\"OPTIMIZE `{table_name}`\")\n","        spark.sql(f\"VACUUM `{table_name}` RETAIN 168 HOURS\")\n","\n","        spark.sql(f\"REFRESH TABLE `{table_name}`\")\n","        spark.sql(f\"ANALYZE TABLE `{table_name}` COMPUTE STATISTICS\")\n","        \n","        print(f\"[{datetime.now()}] Completed refresh for table: {table_name}\")\n","        return f\"Success: {table_name}\"\n","        \n","    except Exception as e:\n","        error_msg = f\"Failed to refresh {table_name}: {str(e)}\"\n","        print(f\"[{datetime.now()}] {error_msg}\")\n","        return f\"Error: {error_msg}\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":51,"statement_ids":[51],"state":"finished","livy_statement_state":"available","session_id":"219fdb7d-abb8-4ba0-95f0-b34ffba044e7","normalized_state":"finished","queued_time":"2025-09-26T23:47:24.9546668Z","session_start_time":null,"execution_start_time":"2025-09-26T23:47:25.3793516Z","execution_finish_time":"2025-09-26T23:47:25.6555421Z","parent_msg_id":"8174085d-9fe6-49ff-88e1-73776f82b93d"},"text/plain":"StatementMeta(, 219fdb7d-abb8-4ba0-95f0-b34ffba044e7, 51, Finished, Available, Finished)"},"metadata":{}}],"execution_count":49,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d24f76e6-e058-43a3-b332-c70096a43bf1"},{"cell_type":"markdown","source":["### Set Variables To Be Used\n","\n","1. max_workers - Adjust this based on your Fabric capacity or Notebook Environment limits\n","2. timeout_limit - Max time (seconds) limit a worker is allowed to run \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"539ff5bd-c1b5-4a70-9482-ac7921546884"},{"cell_type":"code","source":["max_workers = 5\n","timeout_limit = 300\n","table_list = {\n","    \"fake_erp_dbo_customer\",\n","    \"fake_erp_dbo_purchase_order\"\n","}\n","\n","# Alternative approach is get ALL the tables in the lakehouse\n","# table_list = get_table_list()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":52,"statement_ids":[52],"state":"finished","livy_statement_state":"available","session_id":"219fdb7d-abb8-4ba0-95f0-b34ffba044e7","normalized_state":"finished","queued_time":"2025-09-26T23:47:25.0122743Z","session_start_time":null,"execution_start_time":"2025-09-26T23:47:25.6576722Z","execution_finish_time":"2025-09-26T23:47:25.9559979Z","parent_msg_id":"8845e478-4ae1-418e-9897-21044267758f"},"text/plain":"StatementMeta(, 219fdb7d-abb8-4ba0-95f0-b34ffba044e7, 52, Finished, Available, Finished)"},"metadata":{}}],"execution_count":50,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1233f820-a6d1-4138-b403-ff70afc1ec97"},{"cell_type":"markdown","source":["### Process Tables Concurrently\n","\n","For more information on concurrent.futures visit https://docs.python.org/3/library/concurrent.futures.html"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ec2451d0-bd41-4ef2-b85f-181e8933a20d"},{"cell_type":"code","source":["job_start_time = datetime.now()\n","print(f\"[{job_start_time}] Job Starting\")\n","    \n","with ThreadPoolExecutor(max_workers=max_workers) as executor:\n","    future_to_table = {\n","        executor.submit(refresh_table, table): table for table in table_list\n","    }\n","    \n","    for future in concurrent.futures.as_completed(future_to_table):\n","        table_name = future_to_table[future]\n","        try:\n","            result = future.result(timeout=timeout_limit)\n","        except concurrent.futures.TimeoutError:\n","            error_msg = f\"Timeout: {table_name} took longer than 5 minutes\"\n","            print(f\"[{datetime.now()}] {error_msg}\")\n","        except Exception as exc:\n","            error_msg = f\"Exception for {table_name}: {exc}\"\n","            print(f\"[{datetime.now()}] {error_msg}\")\n","\n","job_end_time = datetime.now()\n","job_duration = (job_end_time - job_start_time).total_seconds()\n","\n","print(f\"[{datetime.now()}] Job Completed in {job_duration:.1f} seconds\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1de5c0e3-f57b-4b55-98ea-0f33a6867222"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"522f9d43-eedc-4d1f-8dbc-5cceb4228818"}],"default_lakehouse":"522f9d43-eedc-4d1f-8dbc-5cceb4228818","default_lakehouse_name":"lab_lakehouse","default_lakehouse_workspace_id":"1ccd4a8b-bfc2-49b8-85f8-f202631243ef"}}},"nbformat":4,"nbformat_minor":5}